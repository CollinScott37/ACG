{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0\n",
    "# All the needed imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#%pip install nltk\n",
    "import nltk\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency    deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP  2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD  2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD  2013-02-26  45000.0   \n",
       "3           Music         Music      USD  2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD  2015-08-29  19500.0   \n",
       "\n",
       "              launched  pledged     state  backers country  usd pledged  \\\n",
       "0  2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1  2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2  2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3  2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4  2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1\n",
    "# Load the raw data\n",
    "\n",
    "original_df = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "# Remove all nans\n",
    "original_df = original_df.dropna()\n",
    "display(original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>goal</th>\n",
       "      <th>durration</th>\n",
       "      <th>start_month</th>\n",
       "      <th>end_month</th>\n",
       "      <th>start_day_name</th>\n",
       "      <th>end_day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>failed</td>\n",
       "      <td>GB</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>59</td>\n",
       "      <td>August</td>\n",
       "      <td>October</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>60</td>\n",
       "      <td>September</td>\n",
       "      <td>November</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>45</td>\n",
       "      <td>January</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2012-03-17</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>30</td>\n",
       "      <td>March</td>\n",
       "      <td>April</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>canceled</td>\n",
       "      <td>US</td>\n",
       "      <td>19500.00</td>\n",
       "      <td>56</td>\n",
       "      <td>July</td>\n",
       "      <td>August</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency   deadline   launched     state  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09 2015-08-11    failed   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01 2017-09-02    failed   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26 2013-01-12    failed   \n",
       "3           Music         Music      USD 2012-04-16 2012-03-17    failed   \n",
       "4    Film & Video  Film & Video      USD 2015-08-29 2015-07-04  canceled   \n",
       "\n",
       "  country      goal  durration start_month end_month start_day_name  \\\n",
       "0      GB   1533.95         59      August   October        Tuesday   \n",
       "1      US  30000.00         60   September  November       Saturday   \n",
       "2      US  45000.00         45     January  February       Saturday   \n",
       "3      US   5000.00         30       March     April       Saturday   \n",
       "4      US  19500.00         56        July    August       Saturday   \n",
       "\n",
       "  end_day_name  \n",
       "0       Friday  \n",
       "1    Wednesday  \n",
       "2      Tuesday  \n",
       "3       Monday  \n",
       "4     Saturday  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2\n",
    "# Reorganize the data\n",
    "\n",
    "# Drop the following columns: ID, usd_pledged, usd_pledged_real, usd_goal_real\n",
    "df = original_df.drop(\n",
    "    [\"pledged\", \"usd pledged\", \"usd_pledged_real\", \"goal\", \"backers\"], axis=1\n",
    ")\n",
    "\n",
    "# Rename the columns\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"ID\": \"id\",\n",
    "        \"name\": \"name\",\n",
    "        \"category\": \"category\",\n",
    "        \"main_category\": \"main_category\",\n",
    "        \"deadline\": \"deadline\",\n",
    "        \"launched\": \"launched\",\n",
    "        \"state\": \"state\",\n",
    "        \"currency\": \"currency\",\n",
    "        \"country\": \"country\",\n",
    "        \"usd_goal_real\": \"goal\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conver the launch and deadline to year-month-day\n",
    "df['launched'] = pd.to_datetime(pd.to_datetime(df['launched'], format=\"%Y-%m-%d %H:%M:%S\").dt.date)\n",
    "df['deadline'] = pd.to_datetime(pd.to_datetime(df['deadline'], format=\"%Y-%m-%d\").dt.date)\n",
    "\n",
    "# Calculate the amount of days between launch and deadline\n",
    "df['durration'] = (df['deadline'] - df['launched']).dt.days\n",
    "df['start_month'] = df['launched'].dt.month_name()\n",
    "df['end_month'] = df['deadline'].dt.month_name()\n",
    "df['start_day_name'] = df['launched'].dt.day_name()\n",
    "df['end_day_name'] = df['deadline'].dt.day_name()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374860, 15)\n",
      "(331462, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>goal</th>\n",
       "      <th>durration</th>\n",
       "      <th>start_month</th>\n",
       "      <th>end_month</th>\n",
       "      <th>start_day_name</th>\n",
       "      <th>end_day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>failed</td>\n",
       "      <td>GB</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>59</td>\n",
       "      <td>August</td>\n",
       "      <td>October</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>60</td>\n",
       "      <td>September</td>\n",
       "      <td>November</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>45</td>\n",
       "      <td>January</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2012-03-17</td>\n",
       "      <td>failed</td>\n",
       "      <td>US</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>30</td>\n",
       "      <td>March</td>\n",
       "      <td>April</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000014025</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>successful</td>\n",
       "      <td>US</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>35</td>\n",
       "      <td>February</td>\n",
       "      <td>April</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000014025                               Monarch Espresso Bar   \n",
       "\n",
       "         category main_category currency   deadline   launched       state  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09 2015-08-11      failed   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01 2017-09-02      failed   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26 2013-01-12      failed   \n",
       "3           Music         Music      USD 2012-04-16 2012-03-17      failed   \n",
       "4     Restaurants          Food      USD 2016-04-01 2016-02-26  successful   \n",
       "\n",
       "  country      goal  durration start_month end_month start_day_name  \\\n",
       "0      GB   1533.95         59      August   October        Tuesday   \n",
       "1      US  30000.00         60   September  November       Saturday   \n",
       "2      US  45000.00         45     January  February       Saturday   \n",
       "3      US   5000.00         30       March     April       Saturday   \n",
       "4      US  50000.00         35    February     April         Friday   \n",
       "\n",
       "  end_day_name  \n",
       "0       Friday  \n",
       "1    Wednesday  \n",
       "2      Tuesday  \n",
       "3       Monday  \n",
       "4       Friday  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print start shape\n",
    "print(df.shape)\n",
    "\n",
    "# Keep only success or fail\n",
    "df = df[(df['state'] == 'failed') | (df['state'] == 'successful')]\n",
    "\n",
    "# Remove country\n",
    "df = df[df['country'] != 'N,0\"']\n",
    "\n",
    "# df = df.drop(columns=['currency', 'country'], axis=1)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Print end shape\n",
    "print(df.shape)\n",
    "\n",
    "# Final data before one hot encoding everything\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4769713764f5198298137ab940c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/331462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m     data_df \u001b[39m=\u001b[39m data_df\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat([df, data_df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m df \u001b[39m=\u001b[39m sentiment_analysis(df, \u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36msentiment_analysis\u001b[1;34m(df, name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m tqdm(df\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(df)):\n\u001b[0;32m      5\u001b[0m     text \u001b[39m=\u001b[39m row[name]\n\u001b[1;32m----> 6\u001b[0m     temp \u001b[39m=\u001b[39m sia\u001b[39m.\u001b[39;49mpolarity_scores(text)\n\u001b[0;32m      7\u001b[0m     result\u001b[39m.\u001b[39mappend([temp[\u001b[39m'\u001b[39m\u001b[39mneg\u001b[39m\u001b[39m'\u001b[39m], temp[\u001b[39m'\u001b[39m\u001b[39mneu\u001b[39m\u001b[39m'\u001b[39m], temp[\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m], temp[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m      8\u001b[0m \u001b[39m# Generate column names\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colli\\anaconda3\\envs\\cs484\\lib\\site-packages\\nltk\\sentiment\\vader.py:366\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39m    matched as if it was a normal word in the sentence.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m sentitext \u001b[39m=\u001b[39m SentiText(\n\u001b[0;32m    367\u001b[0m     text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mPUNC_LIST, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mREGEX_REMOVE_PUNCTUATION\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    369\u001b[0m sentiments \u001b[39m=\u001b[39m []\n\u001b[0;32m    370\u001b[0m words_and_emoticons \u001b[39m=\u001b[39m sentitext\u001b[39m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[1;32mc:\\Users\\Colli\\anaconda3\\envs\\cs484\\lib\\site-packages\\nltk\\sentiment\\vader.py:274\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[1;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST \u001b[39m=\u001b[39m punc_list\n\u001b[0;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mREGEX_REMOVE_PUNCTUATION \u001b[39m=\u001b[39m regex_remove_punctuation\n\u001b[1;32m--> 274\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords_and_emoticons \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_words_and_emoticons()\n\u001b[0;32m    275\u001b[0m \u001b[39m# doesn't separate words from\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m# adjacent punctuation (keeps emoticons & contractions)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cap_diff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallcap_differential(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwords_and_emoticons)\n",
      "File \u001b[1;32mc:\\Users\\Colli\\anaconda3\\envs\\cs484\\lib\\site-packages\\nltk\\sentiment\\vader.py:306\u001b[0m, in \u001b[0;36mSentiText._words_and_emoticons\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39mRemoves leading and trailing puncutation\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[39mLeaves contractions and most emoticons\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39m    Does not preserve punc-plus-letter emoticons (e.g. :D)\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m wes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit()\n\u001b[1;32m--> 306\u001b[0m words_punc_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_words_plus_punc()\n\u001b[0;32m    307\u001b[0m wes \u001b[39m=\u001b[39m [we \u001b[39mfor\u001b[39;00m we \u001b[39min\u001b[39;00m wes \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(we) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m    308\u001b[0m \u001b[39mfor\u001b[39;00m i, we \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(wes):\n",
      "File \u001b[1;32mc:\\Users\\Colli\\anaconda3\\envs\\cs484\\lib\\site-packages\\nltk\\sentiment\\vader.py:294\u001b[0m, in \u001b[0;36mSentiText._words_plus_punc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m# the product gives ('cat', ',') and (',', 'cat')\u001b[39;00m\n\u001b[0;32m    293\u001b[0m punc_before \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(p): p[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m product(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST, words_only)}\n\u001b[1;32m--> 294\u001b[0m punc_after \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(p): p[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m product(words_only, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST)}\n\u001b[0;32m    295\u001b[0m words_punc_dict \u001b[39m=\u001b[39m punc_before\n\u001b[0;32m    296\u001b[0m words_punc_dict\u001b[39m.\u001b[39mupdate(punc_after)\n",
      "File \u001b[1;32mc:\\Users\\Colli\\anaconda3\\envs\\cs484\\lib\\site-packages\\nltk\\sentiment\\vader.py:294\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m# the product gives ('cat', ',') and (',', 'cat')\u001b[39;00m\n\u001b[0;32m    293\u001b[0m punc_before \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(p): p[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m product(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST, words_only)}\n\u001b[1;32m--> 294\u001b[0m punc_after \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(p): p[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m product(words_only, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST)}\n\u001b[0;32m    295\u001b[0m words_punc_dict \u001b[39m=\u001b[39m punc_before\n\u001b[0;32m    296\u001b[0m words_punc_dict\u001b[39m.\u001b[39mupdate(punc_after)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sentiment_analysis(df: pd.DataFrame, name):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    result = [] \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row[name]\n",
    "        temp = sia.polarity_scores(text)\n",
    "        result.append([temp['neg'], temp['neu'], temp['pos'], temp['compound']])\n",
    "    # Generate column names\n",
    "    column_names = []\n",
    "    for value in ['negative', 'neutral', 'positive', 'compound']:\n",
    "        column_names.append(f\"{name}_{str(value)}\")\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    data_df = pd.DataFrame(np.array(result), columns=column_names)\n",
    "\n",
    "    # Return the final new DataFrame\n",
    "    # print(new_df.shape)\n",
    "    # print(data_df.dropna().shape)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "    return pd.concat([df, data_df], axis=1)\n",
    "df = sentiment_analysis(df, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(df\u001b[39m.\u001b[39mhead(n\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "display(df.head(n=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_column(df: pd.DataFrame, name):\n",
    "    # The existing column\n",
    "    column = df[name]\n",
    "\n",
    "    # Dataframe without the existing column\n",
    "    new_df = df.drop([name], axis=1)\n",
    "\n",
    "    # Get the unique values\n",
    "    unique = column.unique()\n",
    "    print(unique)\n",
    "\n",
    "    # Create a mapping from the unique value to the index\n",
    "    mapping = {key: index for index, key in enumerate(unique)}\n",
    "\n",
    "    # The encoded data\n",
    "    encoded = np.zeros((df.shape[0], len(unique)))\n",
    "\n",
    "    # Show mapping\n",
    "    # for key, index in mapping.items():\n",
    "    #     temp = np.zeros((len(unique)))\n",
    "    #     temp[index] = 1.0\n",
    "    #     print(f\"{temp}: {key}\")\n",
    "\n",
    "    # Encode each value\n",
    "    for offset, value in enumerate(column):\n",
    "        index = mapping[value]\n",
    "        encoded[offset][index] = 1\n",
    "\n",
    "    # Generate column names\n",
    "    column_names = []\n",
    "    for value in unique:\n",
    "        column_names.append(f\"{name}_{str(value)}\")\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    data_df = pd.DataFrame(encoded, columns=column_names, dtype=np.uint8)\n",
    "\n",
    "    # Return the final new DataFrame\n",
    "    # print(new_df.shape)\n",
    "    # print(data_df.dropna().shape)\n",
    "\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "    return pd.concat([new_df, data_df], axis=1)\n",
    "\n",
    "df = one_hot_encode_column(df, \"category\")\n",
    "df = one_hot_encode_column(df, \"main_category\")\n",
    "df = one_hot_encode_column(df, \"currency\")\n",
    "df = one_hot_encode_column(df, \"country\")\n",
    "df = one_hot_encode_column(df, \"start_month\")\n",
    "df = one_hot_encode_column(df, \"end_month\")\n",
    "df = one_hot_encode_column(df, \"start_day_name\")\n",
    "df = one_hot_encode_column(df, \"end_day_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.copy()\n",
    "df_features = df_features.drop(columns=['name', 'state', 'deadline', 'launched'], axis=1)\n",
    "# Normalize goal and duration\n",
    "df_features['goal'] = (df_features['goal'] - df_features['goal'].mean()) / df_features['goal'].std()\n",
    "df_features['durration'] = (df_features['durration'] - df_features['durration'].mean()) / df_features['durration'].std()\n",
    "# df_features['start_year'] = (df_features['start_year'] - df_features['start_year'].mean()) / df_features['start_year'].std()\n",
    "# df_features['end_year'] = (df_features['end_year'] - df_features['end_year'].mean()) / df_features['end_year'].std()\n",
    "df_labels = df[['id', 'state']]\n",
    "df_labels['state'] = (df['state'] == 'successful').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the min and max years\n",
    "display(df_features.head())\n",
    "print(df['launched'].dt.year.min())\n",
    "print(df['launched'].dt.year.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success_failure_summary(labels):\n",
    "    success_count = labels['state'].sum()\n",
    "    fail_count = labels.shape[0] - success_count \n",
    "    print(f\"# success: {success_count}\")\n",
    "    print(f\"# fail: {fail_count}\")\n",
    "    print(f\"Percent containin success: {round(success_count / labels.shape[0] * 100, 2)}\")\n",
    "    print(f\"Percent containin fail: {round(fail_count / labels.shape[0] * 100, 2)}\")\n",
    "success_failure_summary(df_labels)\n",
    "success_mask = df_labels['state'] == 1\n",
    "success_features = df_features[success_mask]\n",
    "success_labels = df_labels[success_mask]\n",
    "fail_mask = df_labels['state'] != 1\n",
    "fail_features = df_features[fail_mask]\n",
    "fail_labels = df_labels[fail_mask]\n",
    "min_length = min(success_mask.sum(), fail_mask.sum())\n",
    "success_features = success_features.head(min_length)\n",
    "success_labels = success_labels.head(min_length)\n",
    "fail_features = fail_features.head(min_length)\n",
    "fail_labels = fail_labels.head(min_length)\n",
    "final_labels = pd.concat([success_labels, fail_labels], axis=0)\n",
    "final_features =pd.concat([success_features, fail_features], axis=0)\n",
    "print(df_features.shape)\n",
    "print(final_features.shape)\n",
    "display(final_features.head())\n",
    "success_failure_summary(final_labels)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_features, df_labels, test_size=0.20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, final_labels, test_size=0.20)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "display(X_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly Drop all ids\n",
    "final_X_train =  X_train.drop(columns=['id'], axis=1)\n",
    "final_X_test = X_test.drop(columns=['id'], axis=1)\n",
    "final_y_train = y_train.drop(columns=['id'], axis=1)\n",
    "final_y_test = y_test.drop(columns=['id'], axis=1)\n",
    "\n",
    "# PCA\n",
    "# X = final_X_train - np.mean(final_X_train, axis=0)\n",
    "# U, _, _ = np.linalg.svd(X.T, full_matrices=False)\n",
    "# G = U[:, :50]\n",
    "# final_X_train = np.dot(G.T, X.T).T\n",
    "# final_X_test = np.dot(G.T, (final_X_test - np.mean(final_X_test, axis=0)).T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PCA code\n",
    "knn = KNeighborsClassifier(n_neighbors=518, weights='distance', metric='l1')\n",
    "knn.fit(final_X_train, final_y_train.values.ravel())\n",
    "print(f\"{knn.predict(final_X_test[0:10])} vs {final_y_test['state'].values[0:10]}\")\n",
    "\n",
    "# Non-PCA code\n",
    "# knn.fit(final_X_train.values, final_y_train.values.ravel())\n",
    "# print(f\"{knn.predict(final_X_test[0:10])} vs {final_y_test['state'].values[0:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_test = knn.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(final_y_train.shape)\n",
    "print(final_y_test.shape)\n",
    "\n",
    "print(\" --- Training Data ---\")\n",
    "success_failure_summary(y_train)\n",
    "print()\n",
    "\n",
    "print(\" --- Testing Data ---\")\n",
    "success_failure_summary(y_test)\n",
    "print()\n",
    "\n",
    "print(\" --- KNN Report ---\")\n",
    "print(classification_report(final_y_test.values.ravel(), predict_y_test))\n",
    "\n",
    "m = confusion_matrix(final_y_test.values.ravel(), predict_y_test)\n",
    "m = m / m.sum()\n",
    "ConfusionMatrixDisplay(m).plot()\n",
    "plt.show()\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs484venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
